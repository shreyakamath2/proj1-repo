{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00981020-f3a4-4f35-81d2-f1b38178cd69",
   "metadata": {},
   "source": [
    "# Project 1: Part 2 - Data Cleaning\n",
    "## Shreya Kamath\n",
    "## 7/22/2025\n",
    "### A cleanup of the CCM Computing Majors Survey results file with Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b1555-577b-416f-b7b4-4afd2bd3d119",
   "metadata": {},
   "source": [
    "### Step 1 - Installing and importing the Pandas library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1263123b-8396-4572-b1aa-3a9b69605037",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f5f20f-e4c5-45f0-8336-72cdc94347f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e31a7e-e0e9-4e40-a4d7-99814cf0e47f",
   "metadata": {},
   "source": [
    "### Step 2 - Importing the survey results .csv file into a dataframe to work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156fc691-de0f-43ee-9c07-e31020234c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Majors Survey Results - Fall 2024.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6993263-6874-4a31-8d31-b51b9b71f54d",
   "metadata": {},
   "source": [
    "### Step 3 - Exploring the dataset with various Pandas functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60707cab-099b-45be-9f59-e1b2af8e9e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33808d-29de-45b4-941a-221a2c7a07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape\n",
    "#Rows, Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd433b51-5340-4cdc-9567-13641544f8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a52c9d-c30c-4846-91cb-aaff008bda85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc616f5-64fd-4248-86ab-3dae7d37a66d",
   "metadata": {},
   "source": [
    "### Step 4 - Display Data Prior to Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85f7798-d3ad-4852-bd7f-f109452af991",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0864f6b-35ce-49ba-9f45-bb061fd6084f",
   "metadata": {},
   "source": [
    "### Step 5 - Renaming all the columns by number to make the cleaning process easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98f845-c75b-43b0-8601-1b6d53a4e2b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['col1', 'col2', 'col3', 'col4', 'col5', 'col6', 'col7', 'col8', 'col9', 'col10', 'col11', 'col12', 'col13', 'col14', 'col15', 'col16', 'col17', 'col18', 'col19', 'col20','col21', 'col22', 'col23', 'col24', 'col25', 'col26', 'col27', 'col28', 'col29', 'col30','col31', 'col32', 'col33', 'col34', 'col35', 'col36', 'col37', 'col38', 'col39', 'col40', 'col41', 'col42', 'col43', 'col44', 'col45', 'col46', 'col47', 'col48', 'col49', 'col50', 'col51', 'col52', 'col53', 'col54', 'col55', 'col56', 'col57', 'col58', 'col59', 'col60','col61', 'col62', 'col63', 'col64', 'col65', 'col66', 'col67', 'col68', 'col69', 'col70','col71', 'col72', 'col73', 'col74', 'col75', 'col76', 'col77', 'col78', 'col79', 'col80','col81', 'col82', 'col83', 'col84', 'col85', 'col86', 'col87', 'col88', 'col89', 'col90']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6616b19a-2af6-400c-aa1b-46328afd8d85",
   "metadata": {},
   "source": [
    "#### Note - I used the .columns method to rename all the columns by number because I didn't want to create a dictionary that had to map a new column name to each of the 90 existing columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294337f2-5b9d-4612-a6aa-95fe4f2a7524",
   "metadata": {},
   "source": [
    "### Step 6 - Dropping the columns which contain information that is unnecessary for my data questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b388abd1-02ae-48f4-9b40-db4edb93ba01",
   "metadata": {},
   "source": [
    "#### By inspecting the original .csv file, I noticed that a lot of the data would not help me answer my questions, so I decided to note these data ranges and remove them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3937da0a-6bf4-43bc-a3f6-6e4b9f8ff34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop([f'col{i}' for i in range(33, 63)], axis=1, inplace=True)\n",
    "df.drop([f'col{i}' for i in range(64, 85)], axis=1, inplace=True)\n",
    "df.drop('col87', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee537f20-3f75-46de-9bea-a2ccae32955c",
   "metadata": {},
   "source": [
    "#### Source: I used a SparkBy tutorial to learn how to drop multiple columns of a dataset at once\n",
    "\n",
    "#### I had originally created a for loop that generated the number of the column I wanted to drop and appended it to 'col' to create the locator. However, it wasn't working, so I prompted ChatGPT and asked for a solution that would allow it to work, and it provided me with the integrated iterator and f string solution\n",
    "\n",
    "#### Source Link: https://sparkbyexamples.com/pandas/pandas-drop-multiple-columns-from-dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f417f51-23a8-407e-a0e4-3a2b542af473",
   "metadata": {},
   "source": [
    "### Step 7 - Renaming the remaining columns with descriptive names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fec86d-46a2-4681-9525-124fdba4a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['timestamp', 'course', 'hear_website', 'hear_social', 'hear_community', 'hear_family', 'hear_student', 'hear_alumni', 'hear_teacher', 'hear_counselor', 'hear_app', 'hear_employer', 'hear_billboard', 'hear_tv', 'hear_radio', 'hear_other', 'impact_affordability', 'impact_location', 'impact_programs', 'impact_online', 'impact_referral', 'impact_faculty', 'impact_reputation', 'impact_finaid', 'impact_scholarships', 'impact_size', 'impact_ecs', 'impact_acceptcred', 'impact_negative', 'impact_njstars', 'impact_transferability', 'impact_hscredit', 'major', 'choice', 'interest', 'gender', 'race', 'age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8eaea-4e76-4b48-8bbe-2f34cb08a5f9",
   "metadata": {},
   "source": [
    "### Step 8 - Filling in any NaNs with contexual data values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03460a3e-4406-42ee-b560-4736401d1c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna({'course': 'Course Unknown'}, inplace=True)\n",
    "df.fillna({'impact_affordability': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_location': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_programs': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_online': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_referral': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_faculty': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_reputation': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_finaid': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_scholarships': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_size': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_ecs': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_acceptcred': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_negative': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_njstars': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_transferability': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_hscredit': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'impact_hscredit': 'Not Applicable'}, inplace=True)\n",
    "df.fillna({'choice': 'Non-Major'}, inplace=True)\n",
    "df.fillna({'interest': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9966cb4-c91a-45ae-bf9e-60ccf02d9906",
   "metadata": {},
   "source": [
    "#### Justifications for these contexual data values\n",
    "#### Courses - Adding course unknown makes it easier for me to remove these records later on\n",
    "#### Impact - Not Applicable was a valid option in the survey, however it was recorded as N/A, causing the responses to appear as NaNs in the dataset\n",
    "#### Choice - This was a question only applicable to students in the major, so any blank responses were from non-majors who skipped the question\n",
    "#### Interest - The non-major students were asked to rank their interest on a scale of 1-5, so I used a number that was not in the range to fill in the blanks left by computing-major students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0647a8fb-47fe-4c7c-bb4e-e3aeab3d81c7",
   "metadata": {},
   "source": [
    "### Step 9 - Removing two records with unknown courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b626b3d9-ce17-4255-8664-0ede625773b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['course'] == 'Course Unknown'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c99cd3d-60e2-495e-aa79-e71ec85447c1",
   "metadata": {},
   "source": [
    "### Step 10 - Displaying the cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2955f999-2f88-437d-a27b-24839e8ace6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2351cf7e-eb86-48e2-9e93-791010ba43a4",
   "metadata": {},
   "source": [
    "### Step 11 - Reading the cleaned dataset into a new .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d821a4b-6dba-4905-a6f6-c6d3ce36c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('cleaned_survey.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc329ff9-c3ae-4a10-9bd1-a13768574a70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
